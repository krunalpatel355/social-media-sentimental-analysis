{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ceae71-e0fc-4a9b-97dd-6537b2047aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching hot posts from r/woodworking...\n",
      "Fetching new posts from r/woodworking...\n",
      "Fetching rising posts from r/woodworking...\n",
      "Fetching controversial posts from r/woodworking...\n",
      "Fetching top posts from r/woodworking...\n",
      "Fetching hot posts from r/astrophotography...\n",
      "Fetching new posts from r/astrophotography...\n",
      "Fetching rising posts from r/astrophotography...\n",
      "Fetching controversial posts from r/astrophotography...\n",
      "Fetching top posts from r/astrophotography...\n",
      "Fetching hot posts from r/birding...\n",
      "Fetching new posts from r/birding...\n",
      "Fetching rising posts from r/birding...\n",
      "Fetching controversial posts from r/birding...\n",
      "Fetching top posts from r/birding...\n",
      "Fetching hot posts from r/urbanplanning...\n",
      "Fetching new posts from r/urbanplanning...\n",
      "Fetching rising posts from r/urbanplanning...\n",
      "Fetching controversial posts from r/urbanplanning...\n",
      "Fetching top posts from r/urbanplanning...\n",
      "Fetching hot posts from r/archaeology...\n",
      "Fetching new posts from r/archaeology...\n",
      "Fetching rising posts from r/archaeology...\n",
      "Fetching controversial posts from r/archaeology...\n",
      "Fetching top posts from r/archaeology...\n",
      "Fetching hot posts from r/mycology...\n",
      "Fetching new posts from r/mycology...\n",
      "Fetching rising posts from r/mycology...\n",
      "Fetching controversial posts from r/mycology...\n",
      "Fetching top posts from r/mycology...\n",
      "Fetching hot posts from r/linguistics...\n",
      "Fetching new posts from r/linguistics...\n",
      "Fetching rising posts from r/linguistics...\n",
      "Fetching controversial posts from r/linguistics...\n",
      "Fetching top posts from r/linguistics...\n",
      "Fetching hot posts from r/boardgames...\n",
      "Fetching new posts from r/boardgames...\n",
      "Fetching rising posts from r/boardgames...\n",
      "Fetching controversial posts from r/boardgames...\n",
      "Fetching top posts from r/boardgames...\n",
      "Fetching hot posts from r/tabletopgamedesign...\n",
      "Fetching new posts from r/tabletopgamedesign...\n",
      "Fetching rising posts from r/tabletopgamedesign...\n",
      "Fetching controversial posts from r/tabletopgamedesign...\n",
      "Fetching top posts from r/tabletopgamedesign...\n",
      "Fetching hot posts from r/lego...\n",
      "Fetching new posts from r/lego...\n",
      "Fetching rising posts from r/lego...\n",
      "Fetching controversial posts from r/lego...\n",
      "Fetching top posts from r/lego...\n",
      "Fetching hot posts from r/bicycling...\n",
      "Fetching new posts from r/bicycling...\n",
      "Fetching rising posts from r/bicycling...\n",
      "Fetching controversial posts from r/bicycling...\n",
      "Fetching top posts from r/bicycling...\n",
      "Fetching hot posts from r/rockclimbing...\n",
      "Fetching new posts from r/rockclimbing...\n",
      "Fetching rising posts from r/rockclimbing...\n",
      "Fetching controversial posts from r/rockclimbing...\n",
      "Fetching top posts from r/rockclimbing...\n",
      "Fetching hot posts from r/astrology...\n",
      "Fetching new posts from r/astrology...\n",
      "Fetching rising posts from r/astrology...\n",
      "Fetching controversial posts from r/astrology...\n",
      "Fetching top posts from r/astrology...\n",
      "Fetching hot posts from r/pagan...\n",
      "Fetching new posts from r/pagan...\n",
      "Fetching rising posts from r/pagan...\n",
      "Fetching controversial posts from r/pagan...\n",
      "Fetching top posts from r/pagan...\n",
      "Fetching hot posts from r/tarot...\n",
      "Fetching new posts from r/tarot...\n",
      "Fetching rising posts from r/tarot...\n",
      "Fetching controversial posts from r/tarot...\n",
      "Fetching top posts from r/tarot...\n",
      "Fetching hot posts from r/aviation...\n",
      "Fetching new posts from r/aviation...\n",
      "Fetching rising posts from r/aviation...\n",
      "Fetching controversial posts from r/aviation...\n",
      "Fetching top posts from r/aviation...\n",
      "Fetching hot posts from r/nasa...\n",
      "Fetching new posts from r/nasa...\n",
      "Fetching rising posts from r/nasa...\n",
      "Fetching controversial posts from r/nasa...\n",
      "Fetching top posts from r/nasa...\n",
      "Fetching hot posts from r/paleontology...\n",
      "Fetching new posts from r/paleontology...\n",
      "Fetching rising posts from r/paleontology...\n",
      "Fetching controversial posts from r/paleontology...\n",
      "Fetching top posts from r/paleontology...\n",
      "Fetching hot posts from r/conlangs...\n",
      "Fetching new posts from r/conlangs...\n",
      "Fetching rising posts from r/conlangs...\n",
      "Fetching controversial posts from r/conlangs...\n",
      "Fetching top posts from r/conlangs...\n",
      "Fetching hot posts from r/speculativeevolution...\n",
      "Fetching new posts from r/speculativeevolution...\n",
      "Fetching rising posts from r/speculativeevolution...\n",
      "Fetching controversial posts from r/speculativeevolution...\n",
      "Fetching top posts from r/speculativeevolution...\n",
      "Fetching hot posts from r/beekeeping...\n",
      "Fetching new posts from r/beekeeping...\n",
      "Fetching rising posts from r/beekeeping...\n",
      "Fetching controversial posts from r/beekeeping...\n",
      "Fetching top posts from r/beekeeping...\n",
      "Fetching hot posts from r/bonsai...\n",
      "Fetching new posts from r/bonsai...\n",
      "Fetching rising posts from r/bonsai...\n",
      "Fetching controversial posts from r/bonsai...\n",
      "Fetching top posts from r/bonsai...\n",
      "Fetching hot posts from r/canning...\n",
      "Fetching new posts from r/canning...\n",
      "Fetching rising posts from r/canning...\n",
      "Fetching controversial posts from r/canning...\n",
      "Fetching top posts from r/canning...\n",
      "Fetching hot posts from r/crafts...\n",
      "Fetching new posts from r/crafts...\n",
      "Fetching rising posts from r/crafts...\n",
      "Fetching controversial posts from r/crafts...\n",
      "Fetching top posts from r/crafts...\n",
      "Fetching hot posts from r/embroidery...\n",
      "Fetching new posts from r/embroidery...\n",
      "Fetching rising posts from r/embroidery...\n",
      "Fetching controversial posts from r/embroidery...\n",
      "Fetching top posts from r/embroidery...\n",
      "Fetching hot posts from r/metalworking...\n",
      "Fetching new posts from r/metalworking...\n",
      "Fetching rising posts from r/metalworking...\n",
      "Fetching controversial posts from r/metalworking...\n",
      "Fetching top posts from r/metalworking...\n",
      "Fetching hot posts from r/lockpicking...\n",
      "Fetching new posts from r/lockpicking...\n",
      "Fetching rising posts from r/lockpicking...\n",
      "Fetching controversial posts from r/lockpicking...\n",
      "Fetching top posts from r/lockpicking...\n",
      "Fetching hot posts from r/trains...\n",
      "Fetching new posts from r/trains...\n",
      "Fetching rising posts from r/trains...\n",
      "Fetching controversial posts from r/trains...\n",
      "Fetching top posts from r/trains...\n",
      "Fetching hot posts from r/campingandhiking...\n",
      "Fetching new posts from r/campingandhiking...\n",
      "Fetching rising posts from r/campingandhiking...\n",
      "Fetching controversial posts from r/campingandhiking...\n",
      "Fetching top posts from r/campingandhiking...\n",
      "Fetching hot posts from r/golf...\n",
      "Fetching new posts from r/golf...\n",
      "Fetching rising posts from r/golf...\n",
      "Fetching controversial posts from r/golf...\n",
      "Fetching top posts from r/golf...\n",
      "Fetching hot posts from r/knitting...\n",
      "Fetching new posts from r/knitting...\n",
      "Fetching rising posts from r/knitting...\n",
      "Fetching controversial posts from r/knitting...\n",
      "Fetching top posts from r/knitting...\n",
      "Fetching hot posts from r/mechanicalkeyboards...\n",
      "Fetching new posts from r/mechanicalkeyboards...\n",
      "Fetching rising posts from r/mechanicalkeyboards...\n",
      "Fetching controversial posts from r/mechanicalkeyboards...\n",
      "Fetching top posts from r/mechanicalkeyboards...\n",
      "Fetching hot posts from r/vintagecomputing...\n",
      "Fetching new posts from r/vintagecomputing...\n",
      "Fetching rising posts from r/vintagecomputing...\n",
      "Fetching controversial posts from r/vintagecomputing...\n",
      "Fetching top posts from r/vintagecomputing...\n",
      "Fetching hot posts from r/classiccars...\n",
      "Fetching new posts from r/classiccars...\n",
      "Fetching rising posts from r/classiccars...\n",
      "Fetching controversial posts from r/classiccars...\n",
      "Fetching top posts from r/classiccars...\n",
      "Fetching hot posts from r/vintagemotorcycles...\n",
      "Fetching new posts from r/vintagemotorcycles...\n",
      "Fetching rising posts from r/vintagemotorcycles...\n",
      "Fetching controversial posts from r/vintagemotorcycles...\n",
      "Fetching top posts from r/vintagemotorcycles...\n",
      "Fetching hot posts from r/overlanding...\n",
      "Fetching new posts from r/overlanding...\n",
      "Fetching rising posts from r/overlanding...\n",
      "Fetching controversial posts from r/overlanding...\n",
      "Fetching top posts from r/overlanding...\n",
      "Fetching hot posts from r/climbing...\n",
      "Fetching new posts from r/climbing...\n",
      "Fetching rising posts from r/climbing...\n",
      "Fetching controversial posts from r/climbing...\n",
      "Fetching top posts from r/climbing...\n",
      "Fetching hot posts from r/ultramarathon...\n",
      "Fetching new posts from r/ultramarathon...\n",
      "Fetching rising posts from r/ultramarathon...\n",
      "Fetching controversial posts from r/ultramarathon...\n",
      "Fetching top posts from r/ultramarathon...\n",
      "Fetching hot posts from r/homebrewing...\n",
      "Fetching new posts from r/homebrewing...\n",
      "Fetching rising posts from r/homebrewing...\n",
      "Fetching controversial posts from r/homebrewing...\n",
      "Fetching top posts from r/homebrewing...\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize Reddit instance with credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"R4aTlqzdkwL8HlP0kbqI_w\",            # Replace with your client_id\n",
    "    client_secret=\"_-xw-M0CWgf3xDc7XMJU3RdCWB9WIQ\", # Replace with your client_secret\n",
    "    user_agent=\"Hazel/1.0 by SeaLimit6194\"\n",
    ")\n",
    "\n",
    "# New list of non-overlapping subreddits covering unique topics\n",
    "subreddits = [\n",
    "    \"woodworking\", \"astrophotography\", \"birding\", \"urbanplanning\", \"archaeology\", \n",
    "    \"mycology\", \"linguistics\", \"boardgames\", \"tabletopgamedesign\", \"lego\", \n",
    "    \"bicycling\", \"rockclimbing\", \"astrology\", \"pagan\", \"tarot\", \n",
    "    \"aviation\", \"nasa\", \"paleontology\", \"conlangs\", \"speculativeevolution\", \n",
    "    \"beekeeping\", \"bonsai\", \"canning\", \"crafts\", \"embroidery\", \n",
    "    \"metalworking\", \"lockpicking\", \"trains\", \"campingandhiking\", \"golf\", \n",
    "    \"knitting\", \"mechanicalkeyboards\", \"vintagecomputing\", \"classiccars\", \"vintagemotorcycles\", \n",
    "    \"overlanding\", \"climbing\", \"ultramarathon\", \"homebrewing\", \"whiskey\", \n",
    "    \"sailing\", \"surfing\", \"diving\", \"freediving\", \"underwaterphotography\", \n",
    "    \"sneakers\", \"streetwear\", \"rawdenim\", \"fountainpens\", \"minimalism\", \n",
    "    \"budgettravel\", \"solotravel\", \"digitalnomad\", \"productivity\", \"minimalism\", \n",
    "    \"cookingforbeginners\", \"BBQ\", \"sousvide\", \"baking\", \"tea\", \n",
    "    \"homelab\", \"networking\", \"sysadmin\", \"netsec\", \"cloudcomputing\", \n",
    "    \"datacenter\", \"kubernetes\", \"devops\", \"pythonforengineers\", \"datascience\", \n",
    "    \"geology\", \"mining\", \"oilandgasworkers\", \"renewableenergy\", \"mechanicalengineering\", \n",
    "    \"electricalengineering\", \"chemicalengineering\", \"composting\", \"hydroponics\", \"urbanfarming\", \n",
    "    \"mushroomgrowers\", \"vegan\", \"plantbased\", \"herbalism\", \"nutritionfacts\", \n",
    "    \"addiction\", \"adhd\", \"anxiety\", \"mentalhealth\", \"depression\"\n",
    "]\n",
    "\n",
    "# Categories to retrieve posts from\n",
    "categories = [\"hot\", \"new\", \"rising\", \"controversial\", \"top\"]\n",
    "\n",
    "# Settings\n",
    "posts_per_subreddit = 500\n",
    "output_file = \"redditdata1.json\"\n",
    "save_interval = 500  # Save data every 500 posts to reach the target size faster\n",
    "\n",
    "# Load existing data and IDs to avoid duplicates\n",
    "if os.path.exists(output_file):\n",
    "    with open(output_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    existing_ids = {post['id'] for post in data if 'id' in post}\n",
    "else:\n",
    "    data = []\n",
    "    existing_ids = set()\n",
    "\n",
    "# Fetch function with deduplication\n",
    "def fetch_subreddit_posts(subreddit_name, category):\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "    \n",
    "    try:\n",
    "        submissions = getattr(subreddit, category)(limit=posts_per_subreddit)\n",
    "        \n",
    "        for submission in submissions:\n",
    "            if submission.id not in existing_ids:\n",
    "                post_data = {\n",
    "                    \"id\": submission.id,\n",
    "                    \"title\": submission.title,\n",
    "                    \"score\": submission.score,\n",
    "                    \"author\": str(submission.author),\n",
    "                    \"created_utc\": submission.created_utc,\n",
    "                    \"subreddit\": subreddit.display_name,\n",
    "                    \"selftext\": submission.selftext,\n",
    "                    \"url\": submission.url,\n",
    "                    \"category\": category\n",
    "                }\n",
    "                posts.append(post_data)\n",
    "                existing_ids.add(submission.id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {category} posts from r/{subreddit_name}: {e}\")\n",
    "    return posts\n",
    "\n",
    "# Data collection with periodic saving and size limit\n",
    "post_count = 0\n",
    "for _ in range(50):  # Increased loop count to accumulate more data\n",
    "    for subreddit_name in subreddits:\n",
    "        for category in categories:\n",
    "            print(f\"Fetching {category} posts from r/{subreddit_name}...\")\n",
    "            new_posts = fetch_subreddit_posts(subreddit_name, category)\n",
    "            data.extend(new_posts)\n",
    "            post_count += len(new_posts)\n",
    "            time.sleep(2)  # Slightly shorter delay to increase data fetching\n",
    "\n",
    "            # Save periodically to avoid data loss\n",
    "            if post_count >= save_interval:\n",
    "                with open(output_file, \"w\") as f:\n",
    "                    json.dump(data, f, indent=4)\n",
    "                    f.flush()\n",
    "                print(f\"Saved {post_count} posts to {output_file}\")\n",
    "                post_count = 0  # Reset counter after save\n",
    "\n",
    "            # Check file size limit\n",
    "            if os.path.getsize(output_file) >= 500 * 1024 * 1024:  # 500 MB\n",
    "                print(\"Target file size of 500 MB reached. Stopping...\")\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "print(f\"Data collection complete. Saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb4cc8-f93a-4083-b3d7-5748fede228c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d501773-762d-4c1c-ba2e-41a44e5106f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
